# ğŸ§ âš›ï¸ Quantum-Arona RAG Explorer ğŸ­ğŸ“

Willkommen beim Quantum-Arona RAG Explorer! Dieses Projekt ist ein Experimentierfeld fÃ¼r ein **hybrides System**, das klassische KI-Techniken mit quanten-inspirierten Konzepten und einem simulierten "emotionalen Zustand" verbindet, um Fragen auf Basis einer Wissensdatenbank zu beantworten.

Stell dir einen sehr belesenen Assistenten vor, der nicht nur Faktenwissen hat, sondern auch Stimmungen und Assoziationen nutzt, um Informationen zu finden und Antworten zu formulieren. Dieses Projekt simuliert einen solchen Assistenten.

---

## âœ¨ Hauptmerkmale

*   **ğŸ§  Semantisches Netzwerk:** Baut ein Netzwerk aus Konzepten (Knoten) und deren Verbindungen auf, basierend auf Textdaten. Lernt, welche Themen oft gemeinsam auftreten.
*   **âš›ï¸ Quanten-inspirierte Knoten:** Einige Konzept-Knoten nutzen simulierte Quantenschaltkreise (Parametrized Quantum Circuits - PQC), um ihr Verhalten zu modellieren. Dies bringt eine Ebene von Wahrscheinlichkeit und potenziellem "Quantenspringen" (plÃ¶tzliche ZustandsÃ¤nderungen) ins Spiel, die das Finden von Informationen beeinflussen kÃ¶nnen.
*   **ğŸ“œ Retrieval-Augmented Generation (RAG):**
    1.  **Retrieval:** Findet die relevantesten Textabschnitte (Chunks) aus der Wissensdatenbank als Antwort auf eine Nutzerfrage (Prompt). Dieser Prozess wird durch die AktivitÃ¤t im Netzwerk und den "emotionalen Zustand" beeinflusst.
    2.  **Generation:** Nutzt die gefundenen Textabschnitte und den internen Systemzustand (Konzepte, Emotionen, Quanten-Hinweise), um mithilfe eines groÃŸen Sprachmodells (LLM), hier Google Gemini, eine kohÃ¤rente und kontextbezogene Antwort zu formulieren.
*   **ğŸ­ Limbus Affektus (Emotionaler Modulator):** Ein spezieller Knoten simuliert einen globalen "emotionalen Zustand" des Systems basierend auf dem PAD-Modell (Pleasure, Arousal, Dominance). Dieser Zustand **moduliert aktiv** verschiedene Systemteile:
    *   ğŸ” **Retrieval:** Beeinflusst, wie streng nach relevanten Texten gesucht wird (Threshold) und wie Suchergebnisse gewichtet werden (Ranking Bias).
    *   ğŸŒ¡ï¸ **Textgenerierung:** Passt die KreativitÃ¤t/ZufÃ¤lligkeit (Temperatur) des LLMs an.
    *   ğŸ“ **Lernen:** Beeinflusst, wie schnell neue Verbindungen im Netzwerk gestÃ¤rkt werden (Lernrate).
    *   âš›ï¸ **Quanteneffekte:** Moduliert den Einfluss von Quanten-PhÃ¤nomenen (Varianz, Aktivierung) auf das Retrieval-Ranking.
*   **ğŸ“ Selbstlernend:** Das System kann seine eigenen generierten (guten) Antworten nutzen, um sein Wissen zu erweitern und die Verbindungen im Netzwerk weiter zu lernen.
*   **âš™ï¸ Konfigurierbar:** Viele Aspekte des Systems (Netzwerkstruktur, Quantenparameter, Lernraten, RAG-Einstellungen, Limbus-Einfluss) kÃ¶nnen Ã¼ber eine JSON-Datei angepasst werden.
*   **ğŸ’¾ Zustandspersistenz:** Der gesamte gelernte Zustand des Netzwerks (Knoten, Verbindungen, Parameter, verarbeitete Texte) kann gespeichert und geladen werden.
*   **ğŸŒ Interaktive UI:** Eine Web-OberflÃ¤che (basierend auf Streamlit) ermÃ¶glicht das einfache Interagieren mit dem System, das Anpassen von Parametern und das Beobachten des Systemzustands.

---

## ğŸ’¡ Wie funktioniert es? (Konzeptuell)

1.  **Wissen aufbauen (Training):**
    *   Textdokumente (BÃ¼cher, Artikel etc.) werden in kleine Abschnitte (Chunks) zerlegt.
    *   Das System identifiziert SchlÃ¼sselkonzepte (z.B. "Ethik", "KI", "Bewusstsein") in diesen Chunks, die als Knoten im Netzwerk definiert sind.
    *   Wenn mehrere Konzepte gemeinsam in einem Chunk auftreten, wird eine Verbindung zwischen den entsprechenden Knoten im Netzwerk gestÃ¤rkt. Dies geschieht Ã¼ber mehrere DurchlÃ¤ufe (Epochen).
    *   Einige Knoten sind als "Quantenknoten" definiert. Ihre interne "Berechnung" basiert auf einer Simulation von Quantenschaltungen, was zu probabilistischem Verhalten fÃ¼hrt.
    *   Der "Limbus Affektus"-Knoten beobachtet die allgemeine AktivitÃ¤t im Netzwerk und passt seinen eigenen PAD-Zustand (Pleasure, Arousal, Dominance) an.
2.  **Fragen beantworten (Inferenz/RAG):**
    *   **Frage (Prompt):** Der Nutzer stellt eine Frage.
    *   **Netzwerkaktivierung:** Die Frage aktiviert relevante Konzept-Knoten im Netzwerk. Aktivierung breitet sich Ã¼ber die gelernten Verbindungen aus. Quantenknoten werden simuliert. Der Limbus-Zustand wird aktualisiert.
    *   **Retrieval (Suche):** Basierend auf den aktivierten Knoten und *moduliert durch den Limbus-Zustand* sucht das System nach den Text-Chunks, die am besten zur Frage passen. Quanteneffekte und der Limbus-Zustand kÃ¶nnen das Ranking beeinflussen.
    *   **Kontextaufbau:** Die gefundenen Chunks, die aktivierten Konzepte, eventuelle Quantensprung-Hinweise und der *skalierte Limbus-Zustand* werden als Kontext fÃ¼r das LLM vorbereitet.
    *   **Generation (Antwort):** Das LLM (Google Gemini) erhÃ¤lt die Nutzerfrage und den aufbereiteten Kontext. Es wird angewiesen, eine natÃ¼rliche Antwort zu formulieren und dabei den Kontext (inkl. der "Stimmung" aus dem Limbus) zu berÃ¼cksichtigen. Die *durch den Limbus-Zustand modulierte* Temperatur beeinflusst den Stil der Antwort.
    *   **Selbstlernen (Optional):** Wenn die generierte Antwort als nÃ¼tzlich erachtet wird, wird sie zur Wissensbasis hinzugefÃ¼gt und das Netzwerk lernt daraus neue Verbindungen oder stÃ¤rkt bestehende (mit *Limbus-modulierter Lernrate*).
3.  **Zustand:** Der gesamte Zustand des Netzwerks (Knotenparameter, VerbindungsstÃ¤rken, Limbus-Zustand, verarbeitete Chunks) wird gespeichert, damit das System beim nÃ¤chsten Start dort weitermachen kann, wo es aufgehÃ¶rt hat.

---

## ğŸ“ Projektstruktur

```
.
â”œâ”€â”€ quantum_arona_hybrid_llm.py  # Hauptlogik: Klassen fÃ¼r Knoten, Quantensystem, Prozessor, RAG, Limbus etc.
â”œâ”€â”€ qllm_train_hybrid.py         # Skript zum Trainieren/Initialisieren des Netzwerks aus Daten.
â”œâ”€â”€ qllm_streamlit_ui_hybrid.py  # Interaktive Web-OberflÃ¤che mit Streamlit.
â”œâ”€â”€ config_qllm.json             # Konfigurationsdatei (Parameter, Knoten, Dateien).
â”œâ”€â”€ qetp_state.json              # Gespeicherter Zustand des Netzwerks (wird vom Training erstellt/aktualisiert).
â”œâ”€â”€ requirements.txt             # Liste der Python-AbhÃ¤ngigkeiten.
â”œâ”€â”€ training_data/               # Verzeichnis fÃ¼r Trainingsdokumente.
â”‚   â”œâ”€â”€ ethics_ai.md
â”‚   â”œâ”€â”€ philosophy_basics.txt
â”‚   â””â”€â”€ ... (weitere Textdateien)
â”‚   â””â”€â”€ learn.txt                # Datei fÃ¼r selbstgelernte Antworten.
â””â”€â”€ README.md                    # Diese Datei.
```

---

## ğŸš€ Setup & Installation

1.  **Repository klonen:**
    ```bash
    git clone https://github.com/CipherCorePro/Quantum-Augmented-Retrieval.git
    cd Quantum-Augmented-Retrieval
    ```
2.  **Virtuelle Umgebung (Empfohlen):**
    ```bash
    python -m venv venv
    # Windows:
    .\venv\Scripts\activate
    # Linux/Mac:
    source venv/bin/activate
    ```
3.  **AbhÃ¤ngigkeiten installieren:**
    ```bash
    pip install -r requirements.txt
    ```
    *(Stelle sicher, dass `requirements.txt` existiert und die nÃ¶tigen Pakete enthÃ¤lt: `numpy`, `scikit-learn`, `google-generativeai`, `streamlit`, `pandas`, `tqdm` (optional))*
4.  **Google Gemini API Key:**
    *   Besorge dir einen API Key vom [Google AI Studio](https://aistudio.google.com/app/apikey).
    *   Setze den Key als Umgebungsvariable:
        ```bash
        # Windows (Eingabeaufforderung)
        set GEMINI_API_KEY=DEIN_API_KEY
        # Windows (PowerShell)
        $env:GEMINI_API_KEY="DEIN_API_KEY"
        # Linux/Mac
        export GEMINI_API_KEY=DEIN_API_KEY
        ```
    *   Alternativ kannst du den Key als Streamlit Secret speichern, wenn du die App Ã¼ber Streamlit Cloud bereitstellst. Die App versucht, dies als Fallback zu nutzen.
5.  **Trainingsdaten:**
    *   Lege deine Trainings-Textdateien (z.B. `.txt`, `.md`) im Verzeichnis `training_data/` ab.
    *   Passe die Liste `training_files` in `config_qllm.json` an, um auf deine Dateien zu verweisen. Die Datei `learn.txt` wird automatisch fÃ¼r das Self-Learning erstellt.

---

## â–¶ï¸ Benutzung

1.  **(Optional) Konfiguration anpassen:** Bearbeite `config_qllm.json`, um Parameter wie die zu verwendenden Trainingsdateien, die Definition semantischer Knoten, Lernraten, Quantenparameter oder Limbus-Einstellungen anzupassen (siehe Abschnitt "Konfiguration").
2.  **Netzwerk trainieren/initialisieren:** FÃ¼hre das Trainingsskript aus. Dies liest die Trainingsdaten, baut das Netzwerk auf und speichert den initialen Zustand.
    ```bash
    python qllm_train_hybrid.py [Optionen]
    ```
    *   `-c DATEI`: Pfad zur Konfigurationsdatei (default: `config_qllm.json`)
    *   `-s DATEI`: Pfad zur Zustandsdatei (default: `qetp_state.json`)
    *   `-f` oder `--force-rebuild`: Ignoriert eine vorhandene Zustandsdatei und startet komplett neu.
3.  **Interaktive UI starten:** Starte die Streamlit Web-App.
    ```bash
    streamlit run qllm_streamlit_ui_hybrid.py --server.address 0.0.0.0 --server.port 789
    ```
    *   Ã–ffne die angezeigte URL (z.B. `http://<Deine-IP>:789`) in deinem Browser.
    *   In der App kannst du:
        *   Den Zustand laden/speichern.
        *   Prompts eingeben und Antworten generieren lassen.
        *   Den Netzwerkstatus (inkl. Limbus PAD-Zustand) einsehen.
        *   TemporÃ¤r Konfigurationsparameter (z.B. Limbus-Einflussfaktoren) anpassen.
        *   Netzwerkschritte manuell simulieren.
        *   Gelernte Verbindungen inspizieren.

---

## âš™ï¸ Konfiguration (`config_qllm.json`)

Diese JSON-Datei steuert das Verhalten des Systems. Wichtige Abschnitte:

*   `training_files`: Liste der Pfade zu deinen Textdateien fÃ¼r das Training.
*   `semantic_nodes`: Definition der Konzept-Knoten und zugehÃ¶riger SchlÃ¼sselwÃ¶rter.
*   `chunk_size`, `chunk_overlap`: Wie die Texte zerlegt werden.
*   `connection_learning_rate`, `connection_decay_rate`: Wie schnell Verbindungen gelernt und vergessen werden.
*   `use_quantum_nodes`, `default_num_qubits`, `simulation_n_shots`: Steuerung der Quanten-inspirierten Knoten.
*   `enable_rag`, `generator_model_name`, `generator_temperature`: Einstellungen fÃ¼r die Textgenerierung mit Gemini.
*   `enable_self_learning`, `self_learning_file_path`: Steuerung des Selbstlern-Mechanismus.
*   **`limbus_...` Parameter:**
    *   `limbus_num_qubits`, `limbus_emotion_decay`, `limbus_*_sensitivity`: Grundparameter fÃ¼r den Limbus-Knoten selbst.
    *   **`limbus_influence_...`**: **Steuern, wie stark der Limbus-Zustand andere Teile beeinflusst!**
        *   `..._prompt_level`: Wie stark der PAD-Zustand im LLM-Prompt erwÃ¤hnt wird.
        *   `..._temperature_*`: Wie Arousal/Dominance die LLM-Temperatur verÃ¤ndern.
        *   `..._threshold_*`: Wie Arousal/Pleasure den Retrieval-Schwellenwert Ã¤ndern.
        *   `..._ranking_bias_*`: Wie Pleasure das Ranking beeinflusst.
        *   `..._learning_rate_*`: Wie Emotionen die Lernrate beeinflussen.
        *   `..._variance_penalty`, `..._activation_boost`: Wie Emotionen die Quanten-Effekt-Parameter im Retrieval Ã¤ndern.
    *   `limbus_min_*`, `limbus_max_*`: Grenzen fÃ¼r modulierte Werte (z.B. Temperatur, Threshold).

---

## ğŸ’¾ Zustandsdatei (`qetp_state.json`)

Diese Datei ist entscheidend! Sie speichert den gesamten gelernten Zustand des Systems:

*   Alle Knoten (inkl. ihrer internen Parameter, auch Quantenparameter).
*   Alle gelernten Verbindungen und ihre Gewichte.
*   Alle verarbeiteten Text-Chunks und ihre zugeordneten Knoten.
*   Den aktuellen Limbus-Zustand.
*   Die Konfiguration, mit der der Zustand erstellt wurde.
*   Metadaten wie verarbeitete Quellen.

Wenn du das Training (`qllm_train_hybrid.py`) ohne `--force-rebuild` startest oder die UI (`qllm_streamlit_ui_hybrid.py`) lÃ¤dst, wird versucht, aus dieser Datei zu laden, um den Lernfortschritt beizubehalten.

---

## ğŸ”­ ZukÃ¼nftige Ideen

*   Anbindung an echte Quantenhardware (statt Simulation).
*   Ausgefeiltere Quantenschaltkreise fÃ¼r Knoten.
*   Verbesserte Visualisierung des Netzwerks und der Aktivierungsdynamik.
*   Integration weiterer LLMs neben Gemini.
*   Feingranularere Steuerung der Limbus-Modulation (z.B. nicht-lineare Effekte).
*   Evaluierungsmetriken fÃ¼r die QualitÃ¤t von Retrieval und Generierung.

---

## ğŸ¤ Mitwirken

BeitrÃ¤ge sind willkommen! Bitte erstelle einen Issue, um Bugs zu melden oder neue Features zu diskutieren. Pull Requests sind ebenfalls gerne gesehen.

---

## ğŸ“œ Lizenz

Dieses Projekt steht unter der [MIT Lizenz](LICENSE).
